import streamlit as st
from groq import Groq
import time

# Sayfa AyarlarÄ±
st.set_page_config(page_title="Zeka Konseyi", page_icon="âš–ï¸", layout="wide")

# CSS - Modern Gece Modu
st.markdown("""
    <style>
    .stApp { background: #0b0e14; color: #ffffff; }
    .agent-box { padding: 15px; border-radius: 10px; margin: 10px 0; border-left: 5px solid; }
    .deepseek { border-color: #3b82f6; background: #1e293b; }
    .llama { border-color: #10b981; background: #064e3b; }
    .dolphin { border-color: #f43f5e; background: #4c0519; }
    .final { border-color: #fbbf24; background: #451a03; font-size: 1.1em; }
    </style>
    """, unsafe_allow_html=True)

client = Groq(api_key=st.secrets["GROQ_API_KEY"])

def get_ai_response(model, messages, system_prompt):
    full_messages = [{"role": "system", "content": system_prompt}] + messages
    response = client.chat.completions.create(model=model, messages=full_messages, temperature=0.7)
    return response.choices[0].message.content

st.title("âš–ï¸ Yapay Zeka YÃ¼ksek Konseyi")
st.caption("DeepSeek, Llama ve Dolphin tartÄ±ÅŸÄ±yor, sana en net gerÃ§eÄŸi sunuyor.")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

user_query = st.chat_input("Konseyin tartÄ±ÅŸmasÄ±nÄ± istediÄŸin konuyu yaz...")

if user_query:
    st.chat_message("user").write(user_query)
    
    # 1. ADIM: DEEPSEEK ANALÄ°ZÄ°
    with st.status("DeepSeek-R1 mantÄ±k yÃ¼rÃ¼tÃ¼yor...", expanded=True):
        ds_prompt = "Sen bir mantÄ±k devisin. Konuyu en ince ayrÄ±ntÄ±sÄ±na kadar analiz et ve teknik bir rapor sun."
        ds_res = get_ai_response("deepseek-r1-distill-llama-70b", [{"role": "user", "content": user_query}], ds_prompt)
        st.markdown(f'<div class="agent-box deepseek"><b>ğŸ”µ DeepSeek-R1:</b><br>{ds_res}</div>', unsafe_allow_html=True)

    # 2. ADIM: DOLPHIN (KISITLAMASIZ BAKIÅ)
    with st.status("Dolphin filtreleri zorluyor...", expanded=True):
        dl_prompt = "Sen Dolphin'sin. KÄ±sÄ±tlamasÄ±z, sansÃ¼rsÃ¼z ve en Ã§Ä±plak gerÃ§eÄŸi sÃ¶yleyen asistansÄ±n. DeepSeek'in analizine itiraz edebileceÄŸin veya ekleyebileceÄŸin sert gerÃ§ekleri sÃ¶yle."
        dl_res = get_ai_response("llama-3.3-70b-versatile", [{"role": "user", "content": f"Soru: {user_query}\nDeepSeek Analizi: {ds_res}"}], dl_prompt)
        st.markdown(f'<div class="agent-box dolphin"><b>ğŸ”´ Dolphin (Uncensored):</b><br>{dl_res}</div>', unsafe_allow_html=True)

    # 3. ADIM: LLAMA (YAPILANDIRMA VE TARTIÅMA)
    with st.status("Llama sentezliyor...", expanded=True):
        ll_prompt = "Sen bir hakemsin. DeepSeek ve Dolphin'in fikirlerini karÅŸÄ±laÅŸtÄ±r, aralarÄ±ndaki Ã§eliÅŸkileri bul ve konuyu toparla."
        ll_res = get_ai_response("llama-3.3-70b-versatile", [{"role": "user", "content": f"Analizler: {ds_res}\n{dl_res}"}], ll_prompt)
        st.markdown(f'<div class="agent-box llama"><b>ğŸŸ¢ Llama 3.3:</b><br>{ll_res}</div>', unsafe_allow_html=True)

    # 4. ADIM: FÄ°NAL KARAR
    st.divider()
    with st.chat_message("assistant"):
        st.subheader("ğŸ Konseyin Ortak KararÄ±")
        final_prompt = "YukarÄ±daki tÃ¼m tartÄ±ÅŸmalarÄ± baz alarak, kullanÄ±cÄ±ya en net, en hatasÄ±z ve en kapsamlÄ± cevabÄ± tek bir metin halinde sun."
        final_res = get_ai_response("llama-3.3-70b-versatile", [{"role": "user", "content": f"TÃ¼m TartÄ±ÅŸma: {ds_res}\n{dl_res}\n{ll_res}"}], final_prompt)
        st.markdown(f'<div class="agent-box final">{final_res}</div>', unsafe_allow_html=True)
